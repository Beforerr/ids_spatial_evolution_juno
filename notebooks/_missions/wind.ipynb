{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: IDs from Wind\n",
    "order: 10\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speasy as spz\n",
    "from speasy import SpeasyIndex\n",
    "from speasy.webservices.generic_archive import user_inventory_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "spz.update_inventories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zijin/Library/Application Support/speasy/archive'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_inventory_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2016-01-01T00:00:00.087500000', '2016-01-01T00:00:00.179500000',\n",
       "       '2016-01-01T00:00:00.271500000', ...,\n",
       "       '2016-01-02T23:59:59.805500000', '2016-01-02T23:59:59.897500000',\n",
       "       '2016-01-02T23:59:59.989500000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = spz.get_data(\n",
    "    'archive/local/WI_H4-RTN_MFI/BRTN',\n",
    "    '2016-01-01',\n",
    "    '2016-01-03',\n",
    ")\n",
    "\n",
    "data.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discontinuitypy.datasets import IDsDataset\n",
    "import polars as pl\n",
    "from fastcore.utils import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = 1 # unit: seconds\n",
    "tau = 60 # unit: seconds\n",
    "\n",
    "mission = \"Wind\"\n",
    "data_dir = '../../data'\n",
    "dir_path = f'{data_dir}/03_primary/{mission}_MAG_ts_{ts}s'\n",
    "state_data_path = f'{data_dir}/03_primary/OMNI_LowRes_ts_3600s.parquet'\n",
    "vec_cols = ['v_x', 'v_y', 'v_z']\n",
    "\n",
    "format = 'arrow'\n",
    "fname = f'events.{mission}.ts_{ts}s_tau_{tau}s.{format}'\n",
    "output_path = f'{data_dir}/05_reporting/{fname}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-Feb-24 16:08:39: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "\n",
      "07-Feb-24 16:08:40: UserWarning: Ray execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    import ray\n",
      "    ray.init()\n",
      "\n",
      "\n",
      "2024-02-07 16:08:42,624\tINFO worker.py:1724 -- Started a local Ray instance.\n",
      "07-Feb-24 16:08:43: UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e528c9af04c46f39c3e8ce08541bc0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Distributing Dataframe:   0%           Elapsed time: 00:00, estimated remaining time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-Feb-24 16:08:43: Using sequential splitting in '.from_pandas()' because of some of the conditions are False: enough_elements=False; all_numeric_types=False; async_mode_on=False\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m UserWarning: Traceback (most recent call last):\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m   File \"/Users/zijin/micromamba/envs/juno/lib/python3.10/site-packages/pdpipe/__init__.py\", line 85, in <module>\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m     from . import skintegrate\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m   File \"/Users/zijin/micromamba/envs/juno/lib/python3.10/site-packages/pdpipe/skintegrate.py\", line 20, in <module>\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m     from sklearn.base import BaseEstimator\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m ModuleNotFoundError: No module named 'sklearn'\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m \n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m UserWarning: pdpipe: Scikit-learn or skutil import failed. Scikit-learn-dependent pipeline stages will not be loaded.\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m UserWarning: Traceback (most recent call last):\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m   File \"/Users/zijin/micromamba/envs/juno/lib/python3.10/site-packages/pdpipe/__init__.py\", line 105, in <module>\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m     from . import nltk_stages\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m   File \"/Users/zijin/micromamba/envs/juno/lib/python3.10/site-packages/pdpipe/nltk_stages.py\", line 19, in <module>\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m     import nltk\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m ModuleNotFoundError: No module named 'nltk'\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m \n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m UserWarning: pdpipe: nltk import failed. nltk-dependent  pipeline stages will not be loaded.\n",
      "\u001b[36m(_deploy_ray_func pid=71808)\u001b[0m UserWarning: Distributing <class 'dict'> object. This may take some time.\n",
      "Distributing Dataframe:   0%           Elapsed time: 00:00, estimated remaining time: ?\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\n",
      "\u001b[36m(_deploy_ray_func pid=71818)\u001b[0m UserWarning: Traceback (most recent call last):\u001b[32m [repeated 22x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71818)\u001b[0m   File \"/Users/zijin/micromamba/envs/juno/lib/python3.10/site-packages/pdpipe/nltk_stages.py\", line 19, in <module>\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71818)\u001b[0m     from . import skintegrate\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71818)\u001b[0m     from sklearn.base import BaseEstimator\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71818)\u001b[0m ModuleNotFoundError: No module named 'sklearn'\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m \u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71818)\u001b[0m UserWarning: pdpipe: Scikit-learn or skutil import failed. Scikit-learn-dependent pipeline stages will not be loaded.\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71818)\u001b[0m     from . import nltk_stages\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71818)\u001b[0m     import nltk\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71818)\u001b[0m ModuleNotFoundError: No module named 'nltk'\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71818)\u001b[0m UserWarning: pdpipe: nltk import failed. nltk-dependent  pipeline stages will not be loaded.\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m UserWarning: Distributing <class 'dict'> object. This may take some time.\u001b[32m [repeated 6664x across cluster]\u001b[0m\n",
      "Distributing Dataframe:   0%           Elapsed time: 00:00, estimated remaining time: ?\u001b[32m [repeated 536x across cluster]\u001b[0m\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\u001b[32m [repeated 6350x across cluster]\u001b[0m\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\u001b[32m [repeated 526x across cluster]\u001b[0m\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71819)\u001b[0m \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71814)\u001b[0m UserWarning: Distributing <class 'dict'> object. This may take some time.\u001b[32m [repeated 8099x across cluster]\u001b[0m\n",
      "Distributing Dataframe:   0%           Elapsed time: 00:00, estimated remaining time: ?\u001b[32m [repeated 515x across cluster]\u001b[0m\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\u001b[32m [repeated 7583x across cluster]\u001b[0m\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\u001b[32m [repeated 514x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f904d06fdb446baf0e12ed8d7ec205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Estimated completion of line 8:   0%           Elapsed time: 00:00, estimated remaining time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_deploy_ray_func pid=71812)\u001b[0m RuntimeWarning: overflow encountered in exp\n",
      "\u001b[36m(_deploy_ray_func pid=71814)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m UserWarning: Distributing <class 'dict'> object. This may take some time.\u001b[32m [repeated 2145x across cluster]\u001b[0m\n",
      "Distributing Dataframe:   0%           Elapsed time: 00:00, estimated remaining time: ?\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\u001b[32m [repeated 1769x across cluster]\u001b[0m\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71813)\u001b[0m RuntimeWarning: overflow encountered in exp\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71808)\u001b[0m RuntimeWarning: overflow encountered in exp\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=71810)\u001b[0m RuntimeWarning: overflow encountered in exp\u001b[32m [repeated 28x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51efa109f8f34443923e39b8b9791047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Distributing Dataframe:   0%           Elapsed time: 00:00, estimated remaining time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-Feb-24 16:09:20: Using sequential splitting in '.from_pandas()' because of some of the conditions are False: enough_elements=False; all_numeric_types=False; async_mode_on=False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45779e0306a241d4899eb66270f58fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Distributing Dataframe:   0%           Elapsed time: 00:00, estimated remaining time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-Feb-24 16:09:20: Using sequential splitting in '.from_pandas()' because of some of the conditions are False: enough_elements=False; all_numeric_types=True; async_mode_on=False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d466dcbcc0e341638502d3a2839f35cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Distributing Dataframe:   0%           Elapsed time: 00:00, estimated remaining time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-Feb-24 16:09:20: Using sequential splitting in '.from_pandas()' because of some of the conditions are False: enough_elements=False; all_numeric_types=False; async_mode_on=False\n"
     ]
    }
   ],
   "source": [
    "events = []\n",
    "for mag_path in files[-1:]:\n",
    "\n",
    "    mag_data = pl.scan_parquet(mag_path).drop('X', 'Y', 'Z').sort('time')\n",
    "    plasma_data = pl.scan_parquet(state_data_path).sort('time')\n",
    "\n",
    "    _events = (\n",
    "        IDsDataset(\n",
    "            mag_data=mag_data,\n",
    "            plasma_data=plasma_data,\n",
    "            tau=tau,\n",
    "            ts=ts,\n",
    "            vec_cols=vec_cols,\n",
    "        )\n",
    "        .find_events(return_best_fit=False)\n",
    "        .update_candidates_with_plasma_data()\n",
    "        .events\n",
    "    )\n",
    "    \n",
    "    events.append(_events)\n",
    "    \n",
    "ids_dataset = IDsDataset(\n",
    "    events=pl.concat(events),\n",
    "    mag_data= pl.scan_parquet(list(walk(dir_path))).drop('X', 'Y', 'Z').sort('time')\n",
    ").export(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the whole data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obsolete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 day of data resampled by 1 sec is about 12 MB.\n",
    "\n",
    "So 1 year of data is about 4 GB, and 6 years of JUNO Cruise data is about 24 GB.\n",
    "\n",
    "Downloading rate is about 250 KB/s, so it will take about 3 days to download all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to download: 126.53 hours\n",
      "Disk space required: 113.88 GB\n",
      "Time to process: 36.50 hours\n"
     ]
    }
   ],
   "source": [
    "num_of_files = 6*365\n",
    "jno_file_size = 12e3\n",
    "thm_file_size = 40e3\n",
    "files_size = jno_file_size + thm_file_size\n",
    "downloading_rate = 250\n",
    "processing_rate = 1/60\n",
    "\n",
    "time_to_download = num_of_files * files_size / downloading_rate / 60 / 60\n",
    "space_required = num_of_files * files_size / 1e6\n",
    "time_to_process = num_of_files / processing_rate / 60 / 60\n",
    "\n",
    "print(f\"Time to download: {time_to_download:.2f} hours\")\n",
    "print(f\"Disk space required: {space_required:.2f} GB\")\n",
    "print(f\"Time to process: {time_to_process:.2f} hours\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
